---
title: "Tarea 3. LSH y Entity matching"
output: html_notebook
---


En este ejemplo veremos como usar LSH 
para encontrar registros
que se refieren al mismo elemento pero están en distintas tablas, 
y pueden diferir en cómo están registrados (entity matching). Vamos a
usar funciones del paquete *textreuse*, aunque puedes usar
también las funciones de las notas.

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. La carpeta del repositorio
es datos/similitud/entity-matching. **El objetivo es parear las dos fuentes para
identificar artículos que se presenteron en las dos referencias.**


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
acm <- read_csv('../datos/similitud/entity_matching/ACM.csv')
dbl <- read_csv('../datos/similitud/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta 1**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer? Si cada tabla contuviera unos 2 millones de documentos, ¿qué tan 
factible sería hacer todas las posibles comparaciones?

```{r}
r1 <- 2294*2616
r1

r2 <- (2294 + 2616)*(2294 + 2616 -1)/2
r2
```
- Tal vez sí se podrían las comparaciones por fuerza bruta con los documentos que cargamos.
- Si la tabla tuviera 2 millones de documentos no sería factible realizar todas las comparaciones.


## Tejas y hashing

Vamos a poner todos los documentos en una sola lista. Aunque al final
encontremos elementos de la misma fuente en la misma cubeta, podemos
filtrar estos.

```{r}
acm_1 <- acm %>% select(id, title, authors) %>% 
  mutate(texto = paste(title, authors, sep = "   ")) %>% 
  mutate(origen = "ACM") %>% 
  mutate(id = as.character(id))
dbl_1 <- dbl %>% select(id, title, authors) %>% 
  mutate(texto = paste(title, authors, sep = "   ")) %>% 
  mutate(origen = "DBL")
acm_dbl <- bind_rows(acm_1, dbl_1)
```

**Pregunta 2**: ¿por qué definimos el texto incluyendo algún espacio en blanco entre título y autor?
¿Qué otra estrategia se te ocurre para convertir en tejas?
- Se agrega el espacio para poder distingir mejor las tejas entre el autor y el título del documento.
- Otra forma podría ser hacer tejas del texto y del autor por separado. Hacer dos tipos de análisis diferentes.
- También podríamos hacer por separado las tejas del autor y el título y al final juntar las dos tejas.



```{r}
# función de las notas
calcular_tejas <- function(x, k = 4, lowercase = FALSE){
  tokenizers::tokenize_character_shingles(x, n = k, lowercase = lowercase,
    simplify = TRUE, strip_non_alpha = FALSE)
}
```

En este caso escogemos 30 hashes agrupados en 10 bandas,
tejas de tamaño 4, y usamos sólo título y autor.


```{r}
library(textreuse)
set.seed(88345)
# usar funciones de textreuse (que hace hash de las tejas directamente)
funciones_minhash <- minhash_generator(30)
nombres <- c(acm_1$id, dbl_1$id)
texto <- c(acm_1$texto, dbl_1$texto)
names(texto) <- nombres
# el siguiente devuelve un objeto con los minhashes calculados
corpus <- TextReuseCorpus(text = texto,
  hash_func = hash_string,
  minhash_func = funciones_minhash,
  tokenizer = calcular_tejas, 
  k = 4, lowercase = TRUE,
  progress = FALSE, skip_short = FALSE)
```

Por ejemplo, para el primer documento tenemos el contenido y los minhashes calculados:

```{r}
corpus[[1]]$content
corpus[[1]]$minhashes
```

Para calcular cubetas y agrupar, primero hacemos una tabla
con los minhashes y la banda de minhashes:

```{r}
minhashes_docs <- minhashes(corpus)
minhashes_tbl <- tibble(doc = names(minhashes_docs),
         minhashes = minhashes_docs) %>% 
  unnest(cols = minhashes) %>% 
  mutate(num_hash = rep(1:30, length(minhashes_docs))) %>%
  mutate(banda = (num_hash - 1) %/% 3 + 1) %>% 
  select(doc, num_hash, banda, minhashes)
  
minhashes_tbl
```

Nótese que hay 3 minhashes en cada banda, y 10 bandas distintas. Ahora
creamos las cubetas:

```{r}
cubetas_tbl <- minhashes_tbl %>% 
  group_by(doc, banda) %>% 
  summarise(buckets = paste(minhashes, collapse = "/")) %>% 
  mutate(buckets = paste(banda, buckets, sep = "/")) 
cubetas_tbl
```

**Pregunta extra (opcional)** Con *textreuse* también puedes
hacer simplemente cubetas_tbl <- lsh(corpus, bands = 10). ¿Cómo crees
que se calculan los identificadores de las cubetas en este caso? 
```{r}
lsh(corpus, bands = 10)
```
- Es similar al "digest" que vimos en clase.
- Lo único que hace es tomar la cadena larga que teníamos y encriptarla.
- La ventaja es que todo se ve más limpio. Hace más difícil que colisionen cubetas.





## Examinar pares candidatos

Ahora extraemos pares similares. En *textreuse* se puede
hacer como sigue:

```{r}
candidatos <- lsh_candidates(cubetas_tbl %>% select(doc, buckets))
nrow(candidatos)
```

Calculamos también la similitud de jaccard exacta para cada par.

```{r}
candidatos <- lsh_compare(candidatos, corpus, jaccard_similarity)
candidatos
```

**Pregunta 4**: explica cómo se calcula la columna *score* en la tabla de candidatos,
y da unos ejemplos.
- Este ya hace una comparación teja por teja para determinar el valor de la similitud de Jaccard entre los pares de documentos posibles.



```{r}
candidatos <- candidatos %>% arrange(desc(score))
candidatos
```

Podemos ver el contenido de un par de esta manera:

```{r}
corpus[["181566"]]$content
corpus[["journals/sigmod/MedeirosP94"]]$content
```


**Pregunta 5**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)? Compara con el total
de comparaciones que es posible hacer entre estas dos tablas.
- Se hicieron 13,273 comparaciones.
- Existen un total de 6,001,104 comparaciones posibles.
- Se redujo mucho la cantidad de trabajo.


Ahora eliminamos candidatos que aparecieron en la misma tabla (misma referencia bibliográfica):


```{r}
candidatos <-  candidatos %>% left_join(acm_dbl %>% select(id, origen) %>% rename(a = id, origen_a = origen))
candidatos <-  candidatos %>% left_join(acm_dbl %>% select(id, origen) %>% rename(b = id, origen_b = origen))
candidatos_dif <- candidatos %>% filter(origen_a != origen_b)
```


**Pregunta 6**: 
¿Cuántos pares candidatos obtuviste?
Examina algunos elementos con similitud uno o cercana a uno. ¿Se refieren al
mismo artículo en las dos fuentes? 
- Se obtuvieron un total de 7,376 pares.
```{r}
corpus[["174642"]]$content
corpus[["journals/tods/CliffordC94"]]$content
```
```{r}
corpus[["191919"]]$content
corpus[["journals/vldb/WhiteD95"]]$content
```
```{r}
corpus[["335434"]]$content
corpus[["conf/sigmod/JagadishKS00"]]$content
```
- Sí, los casos analizados se refieren a la misma fuente.
- Solamente se observan algunas diferencias en materia de mayúsculas y orden de palabras.



**Pregunta 7**: 
¿Cuántos pares candidatos obtienes si usas 30 hashes con 5 o 30 bandas, en
lugar de 10 bandas? Explica cuál es la desventaja de usar demasiadas
bandas, y cuál es la desventaja de usar muy pocas bandas.
- Con 5 bandas
  - Se redujo a 2,560 el número de comparaciones hechas.
  - La ventaja es que se hace más sencillo el algoritmo pero podemos perder comparaciones.
- Con 30 bandas
  - El número de comparaciones subió a 5,512,229.
  - Vamos a poder identificar muchas más similitudes pero va a ser más pesado el algoritmo.


## Examinar resultados

**Pregunta 8**: Ahora considera los elementos 
con similitud más baja que capturaste. Examina varios casos y concluye
si hay pares que no se refieren al mismo artículo, y por qué.
```{r}
candidatos %>% filter(score > 0.4) %>% filter(score < 0.5)
```


```{r}
## 0.01
corpus[["375724"]]$content
corpus[["conf/vldb/ZurekS99"]]$content
```
```{r}
## 0.02
corpus[["673470"]]$content
corpus[["conf/sigmod/LacroixSC98"]]$content
```
```{r}
## 0.032085561
corpus[["872848"]]$content
corpus[["journals/tods/DekhtyarRS01"]]$content
```
```{r}
## 0.5945946
corpus[["641273"]]$content
corpus[["conf/vldb/VeltriCV01"]]$content
```
```{r}
## 0.4932735
corpus[["872835"]]$content
corpus[["conf/vldb/BhattacharjeePMLCH03"]]$content
```




**Pregunta 9**: propón un punto de corte de similitud para la tabla de arriba, según tus
observaciones de la pregunta anterior.

```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
candidatos_filt <- filter(candidatos_dif, score > 0.6)
tail(candidatos_filt)
```





**Pregunta 10**: ¿cuántos pares candidatos obtuviste al final?
- Con un punto de corte de 0.6 obtuve 2,298 candidatos.


## Evaluación de resultados

Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.


```{r}
mapping <- read_csv("../datos/similitud/entity_matching/DBLP-ACM_perfectMapping.csv")
```

Crea variables apropiadas para hacer join de los verdaderos matches con tus candidatos:

```{r}
candidatos_filt <- candidatos_filt %>% mutate(idDBLP = ifelse(str_detect(a, "^[0-9]*$"), b, a))
candidatos_filt <- candidatos_filt %>% mutate(idACM = ifelse(str_detect(a, "^[0-9]*$"), a, b))
```

Podemos calcular el número de pares verdaderos que son candidatos (recuperados), el número de pares
candidatos que son candidatos pero no son pares verdaderos, por ejemplo:

```{r}
mapping <- mapping %>% mutate(idACM = as.character(idACM))
ambos <- inner_join(candidatos_filt, mapping)
nrow(candidatos_filt)
nrow(ambos)
```

*Pregunta 11 *: Evalúa precisión y recall de tu método. Para distintas aplicaciones que te
puedas imaginar, ¿qué tan buenos son estos resultados? ¿Qué consideras
mejor en este punto, tener precisión o recall alto? 

```{r}
precision <- nrow(ambos)/nrow(candidatos_filt)
precision
recall <- nrow(ambos)/nrow(mapping)
recall
```
- Si estamos trabajando una aplicación de plagio, me interesa más enfatizar en el recall.
- Generalmente vamos a querer tener una cobertura alta primero y después refinar el proceso.


## Análisis de errores

Considera algunos casos que fallamos en recuperar como candidatos

```{r}
anti_join(mapping, candidatos_filt) %>% left_join(candidatos_filt)
```

**Pregunta 11**: Considerando estos errores, ¿qué se te ocurre para mejorar el método?
```{r}
corpus[["conf/sigmod/BaulierBGGHJKKMMNNRSSSWW99"]]$content
corpus[["304239"]]$content
```
```{r}
corpus[["373708"]]$content
corpus[["journals/sigmod/MotroA03"]]$content
```

